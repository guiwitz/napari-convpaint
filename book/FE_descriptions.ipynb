{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c089a9ba",
   "metadata": {},
   "source": [
    "# Feature Extractor descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97359a29",
   "metadata": {},
   "source": [
    "Convpaint utilizes a **variety of pre-trained models for feature extraction**, allowing users to choose the most suitable model for their specific task. These models are designed to capture different aspects of the input data, enabling more effective segmentation and analysis. Please refer to the [preprint of the paper](https://doi.org/10.1101/2024.09.12.610926) for a detailed comparison of the models and their performance on various datasets.\n",
    "\n",
    "Convpaint's `FeatureExtractor` class serves as the backbone for feature extraction in the framework, ensuring features are processed and provided in a consistent manner across different models. This also makes it very easy to add new feature extractors—see the provided template in case you want to implement your own, and do not hesitate to reach out to us for assistance.\n",
    "\n",
    "Here, the currently implemented models are described:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef2adea",
   "metadata": {},
   "source": [
    "### VGG16 (CNN)\n",
    "\n",
    "VGG16 is a convolutional neural network model that is 16 layers deep, and is **Convpaint's original feature extractor**. It is known for its simplicity and effectiveness in image classification tasks. The architecture consists of a series of convolutional layers followed by max-pooling layers, and it uses ReLU activations. VGG16 has been widely used as a backbone for various computer vision tasks and is available in many deep learning frameworks.\n",
    "\n",
    "For Convpaint, we recommend only using very **early layers** of VGG16 and combining those in **multiple scales** into a more complex feature representation (feature pyramid).\n",
    "\n",
    "Like this, VGG16 can capture fine-grained details at different resolutions, making it suitable for tasks that require a **high level of spatial awareness**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1444f21",
   "metadata": {},
   "source": [
    "### Ilastik (optional)\n",
    "\n",
    "Ilastik uses **pre-defined filters** (and technically does not count as a pre-trained model). It is a popular tool for interactive image segmentation and classification using local image features.\n",
    "\n",
    "We implemented a workflow in Convpaint that leverages Ilastik's **full filter set** (multiple filters at multiple sizes), and additionally allows the user to combine those in multiple scales into a more complex feature representation (feature pyramid).\n",
    "\n",
    "Like this, Ilastik is effective in segmenting images based on **local image features at different scales**.\n",
    "\n",
    "*Sidenote: The user needs to install `napari-ilastik` in order to use Ilastik in Convpaint, otherwise it will not be available as a feature extractor.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613063bf",
   "metadata": {},
   "source": [
    "### Cellpose (optional)\n",
    "\n",
    "Cellpose is a segmentation model very popular for **biological image analysis**. It is designed to work well with a variety of cell types and imaging conditions, making it a versatile choice for researchers in the life sciences. Cellpose uses a deep learning approach to segment cells in images.\n",
    "\n",
    "In Convpaint, we integrated Cellpose as a feature extractor and recommend considering it for tasks that involve **cell segmentation and analysis**.\n",
    "\n",
    "*Sidenote: The user needs to install `cellpose` in order to use Cellpose in Convpaint, otherwise it will not be available as a feature extractor.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9177a",
   "metadata": {},
   "source": [
    "### Gaussian\n",
    "\n",
    "This is a **minimal feature extractor model**, that only captures features based on a single **gaussian filter**.\n",
    "\n",
    "While it was originally implemented with the goal to showcase how easy new feature extractors can be added to Convpaint, it can still be **useful for its speed in simple tasks** or as a baseline for comparison with more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8719c5",
   "metadata": {},
   "source": [
    "### EfficientNet\n",
    "\n",
    "This is a convolutional neural network from a family of models optimized for **accuracy and efficiency** through compound scaling of depth, width, and resolution.\n",
    "\n",
    "In Convpaint, it can offer a good balance between performance and computational cost for certain tasks. We recommend considering EfficientNet when the task requires **efficient feature extraction with limited resources**, while still retaining a reasonable level of spatial detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f396c",
   "metadata": {},
   "source": [
    "### ConvNeXT\n",
    "\n",
    "ConvNeXT is a **modern convolutional neural network** architecture designed for high-quality feature extraction in image analysis.\n",
    "\n",
    "In Convpaint, we recommend considering ConvNeXT when the task benefits **more from semantic context** than from fine-grained spatial detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5b582",
   "metadata": {},
   "source": [
    "### DINOv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a666ba5",
   "metadata": {},
   "source": [
    "DINOv2 is a self-supervised, vision transformer model trained on large-scale image data to learn **general-purpose visual representations**.\n",
    "\n",
    "In Convpaint, it provides **strong semantic features**. We recommend using DINOv2 when the task benefits from **rich semantic understanding** and transferability across diverse image types, rather than focusing on fine spatial resolution. DINOv2 is particularly effective for tasks that require a deep understanding of image content and context.\n",
    "\n",
    "DINOv2 has shown particularly good results on:\n",
    "- Natural images such as food, objects, people, animals\n",
    "- Medical images like histology slides or x-rays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c12d36",
   "metadata": {},
   "source": [
    "### Jafar DINOv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fb1d5",
   "metadata": {},
   "source": [
    "JAFAR (Jack up Any Feature at Any Resolution) is a lightweight, attention-based **feature upsampler** designed to enhance spatial resolution from any foundation vision encoder to arbitrary output sizes. It fuses low-level image details with semantically enriched low-resolution features, enabling sharper and more spatially precise feature maps—without high-resolution supervision.\n",
    "\n",
    "Given the good results with DINOv2 as a feature extractor, often only limited by the resolution of the input features, we implemented feature extraction using **JAFAR on top of DINOv2**.\n",
    "\n",
    "This is ***the* recommended approach** for tasks that require **high spatial resolution together with rich semantic understanding**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44df4eb",
   "metadata": {},
   "source": [
    "### Combo FEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48362c5",
   "metadata": {},
   "source": [
    "Convpaint's Architecture allows to combine feature extracted from multiple models for training and inference by simply concatenating the feature vectors, treating them like **a single, unified representation** of the input data. This enables the model to **leverage the strengths of each individual feature extractor**, resulting in improved performance across a variety of tasks.\n",
    "\n",
    "Given the models used in Convpaint, we have initially implemented the following **combo models**, whereas it is very straight-forward to define new ones:\n",
    "\n",
    "- **DINOv2 + Guassian** : Semantic understanding with fast, simple, finegrained details\n",
    "- **DINOv2 + VGG16 (small)** : Semantic understanding and rich feature representation with strong spatial awareness\n",
    "- **DINOv2 + Ilastik** : Semantic understanding with local image context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e24e08",
   "metadata": {},
   "source": [
    "## Standard models with aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3726cf",
   "metadata": {},
   "source": [
    "Currently, the following standard models are defined and can be **specified directly by aliases** when initializing a ConvpaintModel:\n",
    "\n",
    "alias | description\n",
    "--- | -\n",
    "\"vgg\":         | standard vgg16 model with 1 layer and 2 scalings\n",
    "\"vgg-m\":       | larger vgg16 model with the first 3 convolutional layers and 3 scalings (1, 2 and 4)\n",
    "\"vgg-l\":       | very large vgg16 model with 5 layers and 4 scalings\n",
    "\"dino\":        | standard dinov2_vits14_reg model (small model with registers, proven to be sufficient for most tasks)\n",
    "\"gaussian\":    | simple gaussian_features model\n",
    "\"cellpose\":    | cellpose_backbone model\n",
    "\"ilastik\":     | ilastik_2d model (without any additional scalings)\n",
    "\"dino-jafar\":  | model extracting dinov2 features (dinov2_vits14_reg) and improving resolution using JAFAR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp-env02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
